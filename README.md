# Truth is Stranger than Fiction 
## Author: Revathi Satkuna

## Problem Statement
- Truth is stranger than fiction. The ENG105MISC class, Creative Writing in Tech, at the local community college wanted to visualize the intersection in English writing and technology.  The professor wanted to demonstrate how language can be generated by AI and in tune how AI can classify different types of text. To help with their learning (being your primary motivator...not money!), you wanted to develop a Classification model to show the students how your computer, with the help of a coding language like Python, can predict where a text can come from. To create the model, and the type of model in question is either going to be a RandomForestClassifier or LogisticRegression, you use the r/creativewriting and r/talesfromtechsupport to classify whether a phrase would belong in the Creative Writing subreddit or in the Technical Support subreddit.  You know you've created a successful model when data is being classified correctly. ## Datasets
### Generated Data
* [`raw_creative_initial_scrape.csv`](./data2/raw_creative_initial_scrape.csv): Raw initial scrap of creative writing subreddit
* [`raw_techsupport_initial_scrape.csv`](./data2/raw_techsupport_initial_scrape.csv): Raw initial scrap of tech support subreddit 
* [`cleaned_creativewriting.csv`](./data2/cleaned_creativewriting.csv): Cleaned and EDA DataFrame of creative writing subreddit
* [`cleaned_techsupport.csv`](./datas2/cleaned_techsupport.csv): Cleaned and EDA DataFrame of tech support subreddit
* [`combo.csv`](./data2/combo.csv): Concatenated cleaned creative writing and tech support subreddit DataFrames

## Data Dictionary
|Feature|Type|Dataset|Description|
|---|---|---|---|
|selftext|object|combo|text from subreddit posts|
|author|object|combo|authors of subreddit posts|
|title|object|combo|titles of subreddit posts|
|subreddit|int64|combo|binary number identifying which subreddit post came from|
|fulltext|object|combo|combining the selftext and title post|
|tokenized_fulltext|object|combo|tokenized fulltext|
|lemmatized_tokenized_fulltext|object|combo|lemmatized tokenized fulltext|
|stemmatized_lemmatized_tokenized_fulltext|object|combo|stemmatized lemmatized tokenized fulltext|


## Executive Summary
- We first used Pushshift's API to collect posts from the r/creativewriting and the r/talesfromtechsupport subreddits. We then clean the data and then perform a binary classification by using Natural Language Processing to train a classifier on which subreddit a given post came from. We clean the data by selecting relevant features from the raw data and removing null values and creating new relevant columns via column transformations. Our most relevant columns were the 'selftext' and the 'title' columns, and we combined those to create a 'fulltext' column. We also assigned a binary value 0 or 1 to the creative writing subreddit posts and the tech support subreddit post in a new column called 'subreddit' so that we can use for Classification modeling later. 
- To prepare our cleaned data for Natural Language Processing, we first used a tokenizer on the fulltext column and then lemmatized and stemmatized it to better prepare it for sentiment analysis and NLP. We then wanted to perform either a CountVectorizer or a TfidfVectorizer to see which one had a better score, we then compare the best scores between a Pipeline with a TfidfVectorizer running into a Multinomial Naive Bayes and then s setting up a BayesSearchCV and then CountVectorizer running into a Multinomial Naive Bayes and then setting up a BayesSearchCV.  TfidfVectorizer had a higher best score, so we used its best parameters it gave for max_features.  We would use the 'stemmatized_lemmatized_tokenized_fulltext' column as our feature and the 'subreddit' column as our target.  
- We then created and compared two models, a Random Forest Classifier and a Logistic Regression Classifier. From there, we compared the baseline score to the accuracy scores of the models, the higher the accuracy score the more successful you have trained your computer to predict whether a phrase corresponds to the Creative Writing and Technical Support subreddits. Since our Logistic Regression model had the highest score, we used it for our visuals.  We  visualized the models by displaying the top positive and negative correlations of the features, corresponding to the Technical Support and Creative Writing subreddits, respectively.  We also plotted the confusion matrix and its metrics to show how effective our model is at predicting whether a set of words will belong into either subreddit.


## Conclusion
- For calculating for whether the text post will be predicted to come from the creative writing subreddit or the tech support subreddit, if you predict that all the posts came from the creative writing subreddit, you would be correct about 58.2 % of the time.  This is because we had more posts from the creative writing subreddit.  For the tech support subreddit, if you predicted that all the posts came from it, you would be right about 41.7% of the time. Since the true positive of this classification matrix would correspond to the tech support reddit, the baseline accuracy would be 41.7%.  
- Our Logistic Regression model had an accuracy of 99.1% and our Random Forest Classifier had an accuracy of 98.7%. 
- After analyzing the confusion matrix generated with the Logistic Regression model, the accuracy was 99.1%.  The sensitivity was 99.5%.  The misclassification rate was 0.9%.  The specificity is 98.7%. The precision is 98.2%.

## Recommendation
- Seeing the results of this model, I am confident that it can be used to classify whether or not a text came from the r/creativewriting and r/talesfromtechsupport.  The class that requested help in this matter will be delighted.  Using this sort of modeling can help us develop any sort of classification model, and mayhaps models more relevant to stakeholders in businesses where money and power are involved. (Assuming there is enough data to work off of!) Since we are just working with college students, the goal is to further their education, but given the goal of financial profit, like in the stock market, you can apply it to a variety of more potentially fruitful circumstances.

